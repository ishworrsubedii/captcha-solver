{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nfhdBa5Ts7ta",
    "outputId": "91b690d8-bed7-4fd7-b2b6-9089e4d5fd2c"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install stow\n",
    "!pip install keras\n",
    "!pip install tf2onnx\n",
    "!pip install mltu"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ByyXJVrcXp6",
    "outputId": "6ad5ac48-da73-4aab-ca6f-fa95bea16d4a"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting stow\n",
      "  Downloading stow-1.3.1-py3-none-any.whl (74 kB)\n",
      "\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/74.8 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━\u001B[0m \u001B[32m71.7/74.8 kB\u001B[0m \u001B[31m2.1 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m74.8/74.8 kB\u001B[0m \u001B[31m1.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stow) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from stow) (4.10.0)\n",
      "Installing collected packages: stow\n",
      "Successfully installed stow-1.3.1\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
      "Collecting tf2onnx\n",
      "  Downloading tf2onnx-1.16.1-py3-none-any.whl (455 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m455.8/455.8 kB\u001B[0m \u001B[31m10.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.25.2)\n",
      "Collecting onnx>=1.4.1 (from tf2onnx)\n",
      "  Downloading onnx-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m15.9/15.9 MB\u001B[0m \u001B[31m55.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (2.31.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.16.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (24.3.7)\n",
      "Requirement already satisfied: protobuf~=3.20 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (3.20.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2024.2.2)\n",
      "Installing collected packages: onnx, tf2onnx\n",
      "Successfully installed onnx-1.16.0 tf2onnx-1.16.1\n",
      "Collecting mltu\n",
      "  Downloading mltu-1.2.4-py3-none-any.whl (79 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m79.4/79.4 kB\u001B[0m \u001B[31m2.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.10/dist-packages (from mltu) (6.0.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mltu) (4.66.2)\n",
      "Collecting qqdm==0.0.7 (from mltu)\n",
      "  Downloading qqdm-0.0.7.tar.gz (5.3 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from mltu) (1.5.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mltu) (1.25.2)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from mltu) (4.8.0.76)\n",
      "Requirement already satisfied: Pillow>=9.4.0 in /usr/local/lib/python3.10/dist-packages (from mltu) (9.4.0)\n",
      "Collecting onnxruntime>=1.15.0 (from mltu)\n",
      "  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.8/6.8 MB\u001B[0m \u001B[31m20.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mltu) (3.7.1)\n",
      "Collecting addict (from qqdm==0.0.7->mltu)\n",
      "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Collecting jupyter (from qqdm==0.0.7->mltu)\n",
      "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Collecting coloredlogs (from onnxruntime>=1.15.0->mltu)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m46.0/46.0 kB\u001B[0m \u001B[31m6.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.0->mltu) (24.3.7)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.0->mltu) (24.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.0->mltu) (3.20.3)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.0->mltu) (1.12)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mltu) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mltu) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mltu) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mltu) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mltu) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mltu) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->mltu) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mltu) (1.16.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.15.0->mltu)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m86.8/86.8 kB\u001B[0m \u001B[31m13.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter->qqdm==0.0.7->mltu) (6.5.5)\n",
      "Collecting qtconsole (from jupyter->qqdm==0.0.7->mltu)\n",
      "  Downloading qtconsole-5.5.1-py3-none-any.whl (123 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m123.4/123.4 kB\u001B[0m \u001B[31m18.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter->qqdm==0.0.7->mltu) (6.1.0)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter->qqdm==0.0.7->mltu) (6.5.4)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter->qqdm==0.0.7->mltu) (5.5.6)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter->qqdm==0.0.7->mltu) (7.7.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.15.0->mltu) (1.3.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->qqdm==0.0.7->mltu) (0.2.0)\n",
      "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->qqdm==0.0.7->mltu) (7.34.0)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->qqdm==0.0.7->mltu) (5.7.1)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->qqdm==0.0.7->mltu) (6.1.12)\n",
      "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->qqdm==0.0.7->mltu) (6.3.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter->qqdm==0.0.7->mltu) (3.6.6)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter->qqdm==0.0.7->mltu) (3.0.10)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter->qqdm==0.0.7->mltu) (3.0.43)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter->qqdm==0.0.7->mltu) (2.16.1)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->qqdm==0.0.7->mltu) (4.9.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->qqdm==0.0.7->mltu) (4.12.3)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->qqdm==0.0.7->mltu) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->qqdm==0.0.7->mltu) (0.7.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->qqdm==0.0.7->mltu) (0.4)\n",
      "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->qqdm==0.0.7->mltu) (3.1.3)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->qqdm==0.0.7->mltu) (5.7.2)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->qqdm==0.0.7->mltu) (0.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->qqdm==0.0.7->mltu) (2.1.5)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->qqdm==0.0.7->mltu) (0.8.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->qqdm==0.0.7->mltu) (0.10.0)\n",
      "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->qqdm==0.0.7->mltu) (5.10.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->qqdm==0.0.7->mltu) (1.5.1)\n",
      "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->qqdm==0.0.7->mltu) (1.2.1)\n",
      "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->qqdm==0.0.7->mltu) (23.2.1)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->qqdm==0.0.7->mltu) (23.1.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->qqdm==0.0.7->mltu) (1.6.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->qqdm==0.0.7->mltu) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->qqdm==0.0.7->mltu) (0.18.1)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->qqdm==0.0.7->mltu) (0.20.0)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->qqdm==0.0.7->mltu) (1.0.0)\n",
      "Collecting qtpy>=2.4.0 (from qtconsole->jupyter->qqdm==0.0.7->mltu)\n",
      "  Downloading QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m93.5/93.5 kB\u001B[0m \u001B[31m15.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->qqdm==0.0.7->mltu) (67.7.2)\n",
      "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->jupyter->qqdm==0.0.7->mltu)\n",
      "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.6/1.6 MB\u001B[0m \u001B[31m43.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->qqdm==0.0.7->mltu) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->qqdm==0.0.7->mltu) (0.7.5)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->qqdm==0.0.7->mltu) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->qqdm==0.0.7->mltu) (0.1.6)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->qqdm==0.0.7->mltu) (4.9.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter->qqdm==0.0.7->mltu) (4.2.0)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter->qqdm==0.0.7->mltu) (1.24.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter->qqdm==0.0.7->mltu) (0.2.4)\n",
      "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter->qqdm==0.0.7->mltu) (2.19.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter->qqdm==0.0.7->mltu) (4.19.2)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter->qqdm==0.0.7->mltu) (0.2.13)\n",
      "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook->jupyter->qqdm==0.0.7->mltu) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter->qqdm==0.0.7->mltu) (21.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter->qqdm==0.0.7->mltu) (2.5)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter->qqdm==0.0.7->mltu) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter->qqdm==0.0.7->mltu) (0.8.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->qqdm==0.0.7->mltu) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->qqdm==0.0.7->mltu) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->qqdm==0.0.7->mltu) (0.34.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->qqdm==0.0.7->mltu) (0.18.0)\n",
      "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->qqdm==0.0.7->mltu) (3.7.1)\n",
      "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->qqdm==0.0.7->mltu) (1.7.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->qqdm==0.0.7->mltu) (1.16.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->qqdm==0.0.7->mltu) (3.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->qqdm==0.0.7->mltu) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->qqdm==0.0.7->mltu) (1.2.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->qqdm==0.0.7->mltu) (2.21)\n",
      "Building wheels for collected packages: qqdm\n",
      "  Building wheel for qqdm (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for qqdm: filename=qqdm-0.0.7-py3-none-any.whl size=6466 sha256=b8176b5e6def5201bc932ef09f221f222e89067caf21fe52e7fa93eeee8a847a\n",
      "  Stored in directory: /root/.cache/pip/wheels/40/1a/56/5dccdea123a172661eb65c8c29fde4567dbda2b72b5fc5893a\n",
      "Successfully built qqdm\n",
      "Installing collected packages: addict, qtpy, jedi, humanfriendly, coloredlogs, onnxruntime, qtconsole, jupyter, qqdm, mltu\n",
      "Successfully installed addict-2.4.0 coloredlogs-15.0.1 humanfriendly-10.0 jedi-0.19.1 jupyter-1.0.0 mltu-1.2.4 onnxruntime-1.17.1 qqdm-0.0.7 qtconsole-5.5.1 qtpy-2.4.1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import tf2onnx\n",
    "import mltu\n",
    "import stow\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)\n",
    "print(\"tf2onnx version:\", tf2onnx.__version__)\n",
    "print(\"MLTU version:\", mltu.__version__)\n",
    "print(\"Stow\", stow.__version__)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JPs0WvVjRzPB",
    "outputId": "9b5b0929-b369-40c4-daa9-3fe6df60dbca"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TensorFlow version: 2.15.0\n",
      "Keras version: 2.15.0\n",
      "tf2onnx version: 1.16.1\n",
      "MLTU version: 1.2.4\n",
      "Stow 1.3.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import shutil\n",
    "\n",
    "shutil.unpack_archive(\"/content/drive/MyDrive/captcha/datasets/train.zip\", \"/content/drive/MyDrive/captcha/datasets\")"
   ],
   "metadata": {
    "id": "jfbcz54Otl1A"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Created By: ishwor subedi\n",
    "Date: 2024-03-27\n",
    "\"\"\"\n",
    "import stow\n",
    "from datetime import datetime\n",
    "\n",
    "from mltu.configs import BaseModelConfigs\n",
    "\n",
    "\n",
    "class ModelConfigs(BaseModelConfigs):\n",
    "    \"\"\"\n",
    "    This class is used to define the model configuration\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model_path = stow.join('/content/drive/MyDrive/captcha/model',\n",
    "                                    datetime.strftime(datetime.now(), \"%Y%m%d%H%M\"))\n",
    "        self.dataset_path = '/content/drive/MyDrive/captcha/datasets/train'\n",
    "        self.splitted_dataset_path = '/content/drive/MyDrive/captcha/final_datasets'\n",
    "        self.vocab = ''\n",
    "        self.height = 50\n",
    "        self.width = 200\n",
    "        self.max_text_length = 0\n",
    "        self.batch_size = 200\n",
    "        self.learning_rate = 0.01\n",
    "        self.train_epochs = 40\n",
    "        self.train_workers = 20\n"
   ],
   "metadata": {
    "id": "4XTlIenKv8cs"
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Created By: ishwor subedi\n",
    "Date: 2024-03-28\n",
    "\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def split_dataset_into_train_and_test(dataset_path, destination_path, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training and testing sets and saves them in the destination path.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset_path: The path to the dataset.\n",
    "    - destination_path: The path where the split datasets will be saved.\n",
    "    - test_size: The proportion of the dataset to include in the test split (default is 0.2).\n",
    "\n",
    "    Returns:\n",
    "    - train_dir: The directory of the training set.\n",
    "    - test_dir: The directory of the testing set.\n",
    "    \"\"\"\n",
    "    # Get all files in the dataset\n",
    "    all_files = [os.path.join(dataset_path, file) for file in os.listdir(dataset_path)]\n",
    "\n",
    "    # Split the files into training and testing sets\n",
    "    train_files, test_files = train_test_split(all_files, test_size=test_size, random_state=42)\n",
    "\n",
    "    # Create directories for the training and testing sets\n",
    "    today_date = datetime.today().strftime('%Y%m%d')\n",
    "    train_dir = os.path.join(destination_path, f\"dataset_{today_date}\", \"train\")\n",
    "    test_dir = os.path.join(destination_path, f\"dataset_{today_date}\", \"test\")\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    for file in train_files:\n",
    "        shutil.copy(file, train_dir)\n",
    "\n",
    "    for file in test_files:\n",
    "        shutil.copy(file, test_dir)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    configs = ModelConfigs()\n",
    "    split_dataset_into_train_and_test(dataset_path=configs.dataset_path, test_size=0.2,\n",
    "                                      destination_path=configs.splitted_dataset_path)\n"
   ],
   "metadata": {
    "id": "WPREx71EuXMU"
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Created By: ishwor subedi\n",
    "Date: 2024-03-28\n",
    "\"\"\"\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "\n",
    "from mltu.tensorflow.model_utils import residual_block\n",
    "\n",
    "\n",
    "def train_model(input_dim, output_dim, activation=\"leaky_relu\", dropout=0.2):\n",
    "    inputs = layers.Input(shape=input_dim, name=\"input\")\n",
    "\n",
    "    # normalize images here instead in preprocessing step\n",
    "    input = layers.Lambda(lambda x: x / 255)(inputs)\n",
    "\n",
    "    x1 = residual_block(input, 16, activation=activation, skip_conv=True, strides=1, dropout=dropout)\n",
    "\n",
    "    x2 = residual_block(x1, 16, activation=activation, skip_conv=True, strides=2, dropout=dropout)\n",
    "    x3 = residual_block(x2, 16, activation=activation, skip_conv=False, strides=1, dropout=dropout)\n",
    "\n",
    "    x4 = residual_block(x3, 32, activation=activation, skip_conv=True, strides=2, dropout=dropout)\n",
    "    x5 = residual_block(x4, 32, activation=activation, skip_conv=False, strides=1, dropout=dropout)\n",
    "\n",
    "    x6 = residual_block(x5, 64, activation=activation, skip_conv=True, strides=2, dropout=dropout)\n",
    "    x7 = residual_block(x6, 32, activation=activation, skip_conv=True, strides=1, dropout=dropout)\n",
    "\n",
    "    x8 = residual_block(x7, 64, activation=activation, skip_conv=True, strides=2, dropout=dropout)\n",
    "    x9 = residual_block(x8, 64, activation=activation, skip_conv=False, strides=1, dropout=dropout)\n",
    "\n",
    "    squeezed = layers.Reshape((x9.shape[-3] * x9.shape[-2], x9.shape[-1]))(x9)\n",
    "\n",
    "    blstm = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(squeezed)\n",
    "    blstm = layers.Dropout(dropout)(blstm)\n",
    "\n",
    "    output = layers.Dense(output_dim + 1, activation=\"softmax\", name=\"output\")(blstm)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model\n"
   ],
   "metadata": {
    "id": "3507ybKBwFm5"
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Created By: ishwor subedi\n",
    "Date: 2024-03-28\n",
    " \"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "    [tf.config.experimental.set_memory_growth(gpu, True) for gpu in tf.config.experimental.list_physical_devices(\"GPU\")]\n",
    "except:\n",
    "    pass\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "from mltu.tensorflow.dataProvider import DataProvider\n",
    "from mltu.tensorflow.losses import CTCloss\n",
    "from mltu.tensorflow.callbacks import Model2onnx, TrainLogger\n",
    "from mltu.tensorflow.metrics import CWERMetric\n",
    "\n",
    "from mltu.preprocessors import ImageReader\n",
    "from mltu.transformers import ImageResizer, LabelIndexer, LabelPadding\n",
    "from mltu.augmentors import RandomBrightness, RandomRotate, RandomErodeDilate\n",
    "from mltu.annotations.images import CVImage\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, train_dir, test_dir):\n",
    "        self.train_dir = train_dir\n",
    "        self.test_dir = test_dir\n",
    "        self.configs = ModelConfigs()\n",
    "        self.vocab = set()\n",
    "        self.max_len = 0\n",
    "\n",
    "    def prepare_data(self, dataset_path):\n",
    "        \"\"\"\n",
    "        Prepares the data for training and testing by reading the images and their labels from the dataset path.\n",
    "        :param dataset_path: The path to the dataset.\n",
    "        :return: A list of image paths and their corresponding labels.\n",
    "        \"\"\"\n",
    "        dataset = []\n",
    "        for file in os.listdir(dataset_path):\n",
    "            file_path = os.path.join(dataset_path, file)\n",
    "            label = os.path.splitext(file)[0]\n",
    "            dataset.append([file_path, label])\n",
    "            self.vocab.update(list(label))\n",
    "            self.max_len = max(self.max_len, len(label))\n",
    "        return dataset\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Trains the model in the custom made architecture and saves the model to the model path.and also prepare the\n",
    "        data in csv format for the training and testing data and convert the .h5 mocdel into onnx format for the\n",
    "        deployment purpose. :return:  None\n",
    "        \"\"\"\n",
    "        train_data = self.prepare_data(self.train_dir)\n",
    "        test_data = self.prepare_data(self.test_dir)\n",
    "\n",
    "        # Save vocab and maximum text length to configs\n",
    "        self.configs.vocab = \"\".join(self.vocab)\n",
    "        self.configs.max_text_length = self.max_len\n",
    "        self.configs.save()\n",
    "\n",
    "        # Create a data provider for the training and testing data\n",
    "        train_data_provider = DataProvider(\n",
    "            dataset=train_data,\n",
    "            skip_validation=True,\n",
    "            batch_size=self.configs.batch_size,\n",
    "            data_preprocessors=[ImageReader(CVImage)],\n",
    "            transformers=[\n",
    "                ImageResizer(self.configs.width, self.configs.height),\n",
    "                LabelIndexer(self.configs.vocab),\n",
    "                LabelPadding(max_word_length=self.configs.max_text_length, padding_value=len(self.configs.vocab))\n",
    "            ],\n",
    "        )\n",
    "        test_data_provider = DataProvider(\n",
    "            dataset=test_data,\n",
    "            skip_validation=True,\n",
    "            batch_size=self.configs.batch_size,\n",
    "            data_preprocessors=[ImageReader(CVImage)],\n",
    "            transformers=[\n",
    "                ImageResizer(self.configs.width, self.configs.height),\n",
    "                LabelIndexer(self.configs.vocab),\n",
    "                LabelPadding(max_word_length=self.configs.max_text_length, padding_value=len(self.configs.vocab))\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # Augment training data with random brightness, rotation and erode/dilate\n",
    "        train_data_provider.augmentors = [RandomBrightness(), RandomRotate(), RandomErodeDilate()]\n",
    "\n",
    "        # Creating TensorFlow model architecture\n",
    "        model = train_model(\n",
    "            input_dim=(self.configs.height, self.configs.width, 3),\n",
    "            output_dim=len(self.configs.vocab),\n",
    "        )\n",
    "\n",
    "        # Compile the model and print summary\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=self.configs.learning_rate),\n",
    "            loss=CTCloss(),\n",
    "            metrics=[CWERMetric(padding_token=len(self.configs.vocab))],\n",
    "            run_eagerly=False\n",
    "        )\n",
    "        model.summary(line_length=110)\n",
    "\n",
    "        # Define path to save the model\n",
    "        os.makedirs(self.configs.model_path, exist_ok=True)\n",
    "\n",
    "        # Define callbacks\n",
    "        earlystopper = EarlyStopping(monitor=\"val_CER\", patience=50, verbose=1, mode=\"min\")\n",
    "        checkpoint = ModelCheckpoint(f\"{self.configs.model_path}/model.h5\", monitor=\"val_CER\", verbose=1,\n",
    "                                     save_best_only=True, mode=\"min\")\n",
    "        trainLogger = TrainLogger(self.configs.model_path)\n",
    "        tb_callback = TensorBoard(f\"{self.configs.model_path}/logs\", update_freq=1)\n",
    "        reduceLROnPlat = ReduceLROnPlateau(monitor=\"val_CER\", factor=0.9, min_delta=1e-10, patience=20, verbose=1,\n",
    "                                           mode=\"min\")\n",
    "        model2onnx = Model2onnx(f\"{self.configs.model_path}/model.h5\")\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(\n",
    "            train_data_provider,\n",
    "            validation_data=test_data_provider,\n",
    "            epochs=self.configs.train_epochs,\n",
    "            callbacks=[earlystopper, checkpoint, trainLogger, reduceLROnPlat, tb_callback, model2onnx],\n",
    "            workers=self.configs.train_workers\n",
    "\n",
    "        )\n",
    "\n",
    "        train_data_provider.to_csv(os.path.join(self.configs.model_path, \"train.csv\"))\n",
    "        test_data_provider.to_csv(os.path.join(self.configs.model_path, \"val.csv\"))\n"
   ],
   "metadata": {
    "id": "UngtusgOwmLr"
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    trainer = ModelTrainer(test_dir='/content/drive/MyDrive/captcha/final_datasets/dataset_20240328/test',\n",
    "                           train_dir='/content/drive/MyDrive/captcha/final_datasets/dataset_20240328/train')\n",
    "    trainer.train()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2iCMlgmNwlBB",
    "outputId": "c3795445-6139-4c73-d8ad-1dbb6d513fcc"
   },
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_1\"\n",
      "______________________________________________________________________________________________________________\n",
      " Layer (type)                    Output Shape                     Param #    Connected to                     \n",
      "==============================================================================================================\n",
      " input (InputLayer)              [(None, 50, 200, 3)]             0          []                               \n",
      "                                                                                                              \n",
      " lambda_1 (Lambda)               (None, 50, 200, 3)               0          ['input[0][0]']                  \n",
      "                                                                                                              \n",
      " conv2d_24 (Conv2D)              (None, 50, 200, 16)              448        ['lambda_1[0][0]']               \n",
      "                                                                                                              \n",
      " batch_normalization_18 (BatchN  (None, 50, 200, 16)              64         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " leaky_re_lu_18 (LeakyReLU)      (None, 50, 200, 16)              0          ['batch_normalization_18[0][0]'] \n",
      "                                                                                                              \n",
      " conv2d_25 (Conv2D)              (None, 50, 200, 16)              2320       ['leaky_re_lu_18[0][0]']         \n",
      "                                                                                                              \n",
      " batch_normalization_19 (BatchN  (None, 50, 200, 16)              64         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " conv2d_26 (Conv2D)              (None, 50, 200, 16)              64         ['lambda_1[0][0]']               \n",
      "                                                                                                              \n",
      " add_9 (Add)                     (None, 50, 200, 16)              0          ['batch_normalization_19[0][0]', \n",
      "                                                                              'conv2d_26[0][0]']              \n",
      "                                                                                                              \n",
      " leaky_re_lu_19 (LeakyReLU)      (None, 50, 200, 16)              0          ['add_9[0][0]']                  \n",
      "                                                                                                              \n",
      " dropout_10 (Dropout)            (None, 50, 200, 16)              0          ['leaky_re_lu_19[0][0]']         \n",
      "                                                                                                              \n",
      " conv2d_27 (Conv2D)              (None, 25, 100, 16)              2320       ['dropout_10[0][0]']             \n",
      "                                                                                                              \n",
      " batch_normalization_20 (BatchN  (None, 25, 100, 16)              64         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " leaky_re_lu_20 (LeakyReLU)      (None, 25, 100, 16)              0          ['batch_normalization_20[0][0]'] \n",
      "                                                                                                              \n",
      " conv2d_28 (Conv2D)              (None, 25, 100, 16)              2320       ['leaky_re_lu_20[0][0]']         \n",
      "                                                                                                              \n",
      " batch_normalization_21 (BatchN  (None, 25, 100, 16)              64         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " conv2d_29 (Conv2D)              (None, 25, 100, 16)              272        ['dropout_10[0][0]']             \n",
      "                                                                                                              \n",
      " add_10 (Add)                    (None, 25, 100, 16)              0          ['batch_normalization_21[0][0]', \n",
      "                                                                              'conv2d_29[0][0]']              \n",
      "                                                                                                              \n",
      " leaky_re_lu_21 (LeakyReLU)      (None, 25, 100, 16)              0          ['add_10[0][0]']                 \n",
      "                                                                                                              \n",
      " dropout_11 (Dropout)            (None, 25, 100, 16)              0          ['leaky_re_lu_21[0][0]']         \n",
      "                                                                                                              \n",
      " conv2d_30 (Conv2D)              (None, 25, 100, 16)              2320       ['dropout_11[0][0]']             \n",
      "                                                                                                              \n",
      " batch_normalization_22 (BatchN  (None, 25, 100, 16)              64         ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " leaky_re_lu_22 (LeakyReLU)      (None, 25, 100, 16)              0          ['batch_normalization_22[0][0]'] \n",
      "                                                                                                              \n",
      " conv2d_31 (Conv2D)              (None, 25, 100, 16)              2320       ['leaky_re_lu_22[0][0]']         \n",
      "                                                                                                              \n",
      " batch_normalization_23 (BatchN  (None, 25, 100, 16)              64         ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " add_11 (Add)                    (None, 25, 100, 16)              0          ['batch_normalization_23[0][0]', \n",
      "                                                                              'dropout_11[0][0]']             \n",
      "                                                                                                              \n",
      " leaky_re_lu_23 (LeakyReLU)      (None, 25, 100, 16)              0          ['add_11[0][0]']                 \n",
      "                                                                                                              \n",
      " dropout_12 (Dropout)            (None, 25, 100, 16)              0          ['leaky_re_lu_23[0][0]']         \n",
      "                                                                                                              \n",
      " conv2d_32 (Conv2D)              (None, 13, 50, 32)               4640       ['dropout_12[0][0]']             \n",
      "                                                                                                              \n",
      " batch_normalization_24 (BatchN  (None, 13, 50, 32)               128        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " leaky_re_lu_24 (LeakyReLU)      (None, 13, 50, 32)               0          ['batch_normalization_24[0][0]'] \n",
      "                                                                                                              \n",
      " conv2d_33 (Conv2D)              (None, 13, 50, 32)               9248       ['leaky_re_lu_24[0][0]']         \n",
      "                                                                                                              \n",
      " batch_normalization_25 (BatchN  (None, 13, 50, 32)               128        ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " conv2d_34 (Conv2D)              (None, 13, 50, 32)               544        ['dropout_12[0][0]']             \n",
      "                                                                                                              \n",
      " add_12 (Add)                    (None, 13, 50, 32)               0          ['batch_normalization_25[0][0]', \n",
      "                                                                              'conv2d_34[0][0]']              \n",
      "                                                                                                              \n",
      " leaky_re_lu_25 (LeakyReLU)      (None, 13, 50, 32)               0          ['add_12[0][0]']                 \n",
      "                                                                                                              \n",
      " dropout_13 (Dropout)            (None, 13, 50, 32)               0          ['leaky_re_lu_25[0][0]']         \n",
      "                                                                                                              \n",
      " conv2d_35 (Conv2D)              (None, 13, 50, 32)               9248       ['dropout_13[0][0]']             \n",
      "                                                                                                              \n",
      " batch_normalization_26 (BatchN  (None, 13, 50, 32)               128        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " leaky_re_lu_26 (LeakyReLU)      (None, 13, 50, 32)               0          ['batch_normalization_26[0][0]'] \n",
      "                                                                                                              \n",
      " conv2d_36 (Conv2D)              (None, 13, 50, 32)               9248       ['leaky_re_lu_26[0][0]']         \n",
      "                                                                                                              \n",
      " batch_normalization_27 (BatchN  (None, 13, 50, 32)               128        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " add_13 (Add)                    (None, 13, 50, 32)               0          ['batch_normalization_27[0][0]', \n",
      "                                                                              'dropout_13[0][0]']             \n",
      "                                                                                                              \n",
      " leaky_re_lu_27 (LeakyReLU)      (None, 13, 50, 32)               0          ['add_13[0][0]']                 \n",
      "                                                                                                              \n",
      " dropout_14 (Dropout)            (None, 13, 50, 32)               0          ['leaky_re_lu_27[0][0]']         \n",
      "                                                                                                              \n",
      " conv2d_37 (Conv2D)              (None, 7, 25, 64)                18496      ['dropout_14[0][0]']             \n",
      "                                                                                                              \n",
      " batch_normalization_28 (BatchN  (None, 7, 25, 64)                256        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " leaky_re_lu_28 (LeakyReLU)      (None, 7, 25, 64)                0          ['batch_normalization_28[0][0]'] \n",
      "                                                                                                              \n",
      " conv2d_38 (Conv2D)              (None, 7, 25, 64)                36928      ['leaky_re_lu_28[0][0]']         \n",
      "                                                                                                              \n",
      " batch_normalization_29 (BatchN  (None, 7, 25, 64)                256        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " conv2d_39 (Conv2D)              (None, 7, 25, 64)                2112       ['dropout_14[0][0]']             \n",
      "                                                                                                              \n",
      " add_14 (Add)                    (None, 7, 25, 64)                0          ['batch_normalization_29[0][0]', \n",
      "                                                                              'conv2d_39[0][0]']              \n",
      "                                                                                                              \n",
      " leaky_re_lu_29 (LeakyReLU)      (None, 7, 25, 64)                0          ['add_14[0][0]']                 \n",
      "                                                                                                              \n",
      " dropout_15 (Dropout)            (None, 7, 25, 64)                0          ['leaky_re_lu_29[0][0]']         \n",
      "                                                                                                              \n",
      " conv2d_40 (Conv2D)              (None, 7, 25, 32)                18464      ['dropout_15[0][0]']             \n",
      "                                                                                                              \n",
      " batch_normalization_30 (BatchN  (None, 7, 25, 32)                128        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " leaky_re_lu_30 (LeakyReLU)      (None, 7, 25, 32)                0          ['batch_normalization_30[0][0]'] \n",
      "                                                                                                              \n",
      " conv2d_41 (Conv2D)              (None, 7, 25, 32)                9248       ['leaky_re_lu_30[0][0]']         \n",
      "                                                                                                              \n",
      " batch_normalization_31 (BatchN  (None, 7, 25, 32)                128        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " conv2d_42 (Conv2D)              (None, 7, 25, 32)                2080       ['dropout_15[0][0]']             \n",
      "                                                                                                              \n",
      " add_15 (Add)                    (None, 7, 25, 32)                0          ['batch_normalization_31[0][0]', \n",
      "                                                                              'conv2d_42[0][0]']              \n",
      "                                                                                                              \n",
      " leaky_re_lu_31 (LeakyReLU)      (None, 7, 25, 32)                0          ['add_15[0][0]']                 \n",
      "                                                                                                              \n",
      " dropout_16 (Dropout)            (None, 7, 25, 32)                0          ['leaky_re_lu_31[0][0]']         \n",
      "                                                                                                              \n",
      " conv2d_43 (Conv2D)              (None, 4, 13, 64)                18496      ['dropout_16[0][0]']             \n",
      "                                                                                                              \n",
      " batch_normalization_32 (BatchN  (None, 4, 13, 64)                256        ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " leaky_re_lu_32 (LeakyReLU)      (None, 4, 13, 64)                0          ['batch_normalization_32[0][0]'] \n",
      "                                                                                                              \n",
      " conv2d_44 (Conv2D)              (None, 4, 13, 64)                36928      ['leaky_re_lu_32[0][0]']         \n",
      "                                                                                                              \n",
      " batch_normalization_33 (BatchN  (None, 4, 13, 64)                256        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " conv2d_45 (Conv2D)              (None, 4, 13, 64)                2112       ['dropout_16[0][0]']             \n",
      "                                                                                                              \n",
      " add_16 (Add)                    (None, 4, 13, 64)                0          ['batch_normalization_33[0][0]', \n",
      "                                                                              'conv2d_45[0][0]']              \n",
      "                                                                                                              \n",
      " leaky_re_lu_33 (LeakyReLU)      (None, 4, 13, 64)                0          ['add_16[0][0]']                 \n",
      "                                                                                                              \n",
      " dropout_17 (Dropout)            (None, 4, 13, 64)                0          ['leaky_re_lu_33[0][0]']         \n",
      "                                                                                                              \n",
      " conv2d_46 (Conv2D)              (None, 4, 13, 64)                36928      ['dropout_17[0][0]']             \n",
      "                                                                                                              \n",
      " batch_normalization_34 (BatchN  (None, 4, 13, 64)                256        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " leaky_re_lu_34 (LeakyReLU)      (None, 4, 13, 64)                0          ['batch_normalization_34[0][0]'] \n",
      "                                                                                                              \n",
      " conv2d_47 (Conv2D)              (None, 4, 13, 64)                36928      ['leaky_re_lu_34[0][0]']         \n",
      "                                                                                                              \n",
      " batch_normalization_35 (BatchN  (None, 4, 13, 64)                256        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " add_17 (Add)                    (None, 4, 13, 64)                0          ['batch_normalization_35[0][0]', \n",
      "                                                                              'dropout_17[0][0]']             \n",
      "                                                                                                              \n",
      " leaky_re_lu_35 (LeakyReLU)      (None, 4, 13, 64)                0          ['add_17[0][0]']                 \n",
      "                                                                                                              \n",
      " dropout_18 (Dropout)            (None, 4, 13, 64)                0          ['leaky_re_lu_35[0][0]']         \n",
      "                                                                                                              \n",
      " reshape_1 (Reshape)             (None, 52, 64)                   0          ['dropout_18[0][0]']             \n",
      "                                                                                                              \n",
      " bidirectional_1 (Bidirectional  (None, 52, 256)                  197632     ['reshape_1[0][0]']              \n",
      " )                                                                                                            \n",
      "                                                                                                              \n",
      " dropout_19 (Dropout)            (None, 52, 256)                  0          ['bidirectional_1[0][0]']        \n",
      "                                                                                                              \n",
      " output (Dense)                  (None, 52, 11)                   2827       ['dropout_19[0][0]']             \n",
      "                                                                                                              \n",
      "==============================================================================================================\n",
      "Total params: 467179 (1.78 MB)\n",
      "Trainable params: 465835 (1.78 MB)\n",
      "Non-trainable params: 1344 (5.25 KB)\n",
      "______________________________________________________________________________________________________________\n",
      "Epoch 1/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 20.9328 - CER: 1.5508 - WER: 1.0000\n",
      "Epoch 1: val_CER improved from inf to 1.00000, saving model to /content/drive/MyDrive/captcha/model/202403281555/model.h5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 88s 2s/step - loss: 20.9328 - CER: 1.5385 - WER: 1.0000 - val_loss: 17.1205 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0100\n",
      "Epoch 2/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 15.6068 - CER: 1.0000 - WER: 1.0000\n",
      "Epoch 2: val_CER did not improve from 1.00000\n",
      "33/33 [==============================] - 61s 2s/step - loss: 15.6068 - CER: 1.0000 - WER: 1.0000 - val_loss: 15.6214 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0100\n",
      "Epoch 3/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 15.5725 - CER: 1.0000 - WER: 1.0000\n",
      "Epoch 3: val_CER did not improve from 1.00000\n",
      "33/33 [==============================] - 63s 2s/step - loss: 15.5725 - CER: 1.0000 - WER: 1.0000 - val_loss: 15.5901 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0100\n",
      "Epoch 4/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 15.5541 - CER: 1.0000 - WER: 1.0000\n",
      "Epoch 4: val_CER did not improve from 1.00000\n",
      "33/33 [==============================] - 71s 2s/step - loss: 15.5541 - CER: 1.0000 - WER: 1.0000 - val_loss: 15.5958 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0100\n",
      "Epoch 5/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 15.5460 - CER: 1.0000 - WER: 1.0000\n",
      "Epoch 5: val_CER did not improve from 1.00000\n",
      "33/33 [==============================] - 65s 2s/step - loss: 15.5460 - CER: 1.0000 - WER: 1.0000 - val_loss: 15.9579 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0100\n",
      "Epoch 6/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 15.5390 - CER: 1.0000 - WER: 1.0000\n",
      "Epoch 6: val_CER did not improve from 1.00000\n",
      "33/33 [==============================] - 62s 2s/step - loss: 15.5390 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.7118 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0100\n",
      "Epoch 7/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 15.5054 - CER: 1.0000 - WER: 1.0000\n",
      "Epoch 7: val_CER did not improve from 1.00000\n",
      "33/33 [==============================] - 63s 2s/step - loss: 15.5054 - CER: 1.0000 - WER: 1.0000 - val_loss: 17.3806 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0100\n",
      "Epoch 8/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 15.4907 - CER: 1.0000 - WER: 1.0000\n",
      "Epoch 8: val_CER did not improve from 1.00000\n",
      "33/33 [==============================] - 61s 2s/step - loss: 15.4907 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.6303 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0100\n",
      "Epoch 9/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 15.4485 - CER: 1.0000 - WER: 1.0000\n",
      "Epoch 9: val_CER did not improve from 1.00000\n",
      "33/33 [==============================] - 63s 2s/step - loss: 15.4485 - CER: 1.0000 - WER: 1.0000 - val_loss: 15.9160 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0100\n",
      "Epoch 10/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 15.4077 - CER: 1.0000 - WER: 1.0000\n",
      "Epoch 10: val_CER did not improve from 1.00000\n",
      "33/33 [==============================] - 62s 2s/step - loss: 15.4077 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.7105 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0100\n",
      "Epoch 11/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 15.1735 - CER: 0.9906 - WER: 1.0000\n",
      "Epoch 11: val_CER did not improve from 1.00000\n",
      "33/33 [==============================] - 62s 2s/step - loss: 15.1735 - CER: 0.9902 - WER: 1.0000 - val_loss: 16.2022 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0100\n",
      "Epoch 12/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 13.3506 - CER: 0.8809 - WER: 1.0000\n",
      "Epoch 12: val_CER improved from 1.00000 to 0.84843, saving model to /content/drive/MyDrive/captcha/model/202403281555/model.h5\n",
      "33/33 [==============================] - 62s 2s/step - loss: 13.3506 - CER: 0.8796 - WER: 1.0000 - val_loss: 17.2510 - val_CER: 0.8484 - val_WER: 1.0000 - lr: 0.0100\n",
      "Epoch 13/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 10.2827 - CER: 0.7018 - WER: 0.9998\n",
      "Epoch 13: val_CER improved from 0.84843 to 0.73131, saving model to /content/drive/MyDrive/captcha/model/202403281555/model.h5\n",
      "33/33 [==============================] - 64s 2s/step - loss: 10.2827 - CER: 0.7010 - WER: 0.9998 - val_loss: 12.1516 - val_CER: 0.7313 - val_WER: 0.9994 - lr: 0.0100\n",
      "Epoch 14/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 8.0687 - CER: 0.5792 - WER: 0.9936\n",
      "Epoch 14: val_CER improved from 0.73131 to 0.56190, saving model to /content/drive/MyDrive/captcha/model/202403281555/model.h5\n",
      "33/33 [==============================] - 62s 2s/step - loss: 8.0687 - CER: 0.5785 - WER: 0.9935 - val_loss: 8.3763 - val_CER: 0.5619 - val_WER: 0.9921 - lr: 0.0100\n",
      "Epoch 15/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 6.3852 - CER: 0.4486 - WER: 0.9616\n",
      "Epoch 15: val_CER did not improve from 0.56190\n",
      "33/33 [==============================] - 60s 2s/step - loss: 6.3852 - CER: 0.4478 - WER: 0.9614 - val_loss: 19.9240 - val_CER: 0.7465 - val_WER: 0.9994 - lr: 0.0100\n",
      "Epoch 16/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 4.9148 - CER: 0.3496 - WER: 0.9052\n",
      "Epoch 16: val_CER did not improve from 0.56190\n",
      "33/33 [==============================] - 62s 2s/step - loss: 4.9148 - CER: 0.3485 - WER: 0.9038 - val_loss: 18.4974 - val_CER: 0.6531 - val_WER: 0.9982 - lr: 0.0100\n",
      "Epoch 17/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 3.5738 - CER: 0.2296 - WER: 0.7381\n",
      "Epoch 17: val_CER improved from 0.56190 to 0.34883, saving model to /content/drive/MyDrive/captcha/model/202403281555/model.h5\n",
      "33/33 [==============================] - 61s 2s/step - loss: 3.5738 - CER: 0.2293 - WER: 0.7374 - val_loss: 5.9369 - val_CER: 0.3488 - val_WER: 0.9125 - lr: 0.0100\n",
      "Epoch 18/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 2.6671 - CER: 0.1749 - WER: 0.6321\n",
      "Epoch 18: val_CER improved from 0.34883 to 0.17011, saving model to /content/drive/MyDrive/captcha/model/202403281555/model.h5\n",
      "33/33 [==============================] - 64s 2s/step - loss: 2.6671 - CER: 0.1747 - WER: 0.6318 - val_loss: 3.0369 - val_CER: 0.1701 - val_WER: 0.6584 - lr: 0.0100\n",
      "Epoch 19/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 2.3637 - CER: 0.1502 - WER: 0.5627\n",
      "Epoch 19: val_CER did not improve from 0.17011\n",
      "33/33 [==============================] - 61s 2s/step - loss: 2.3637 - CER: 0.1499 - WER: 0.5618 - val_loss: 4.8121 - val_CER: 0.2055 - val_WER: 0.7435 - lr: 0.0100\n",
      "Epoch 20/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 1.6766 - CER: 0.0922 - WER: 0.3764\n",
      "Epoch 20: val_CER did not improve from 0.17011\n",
      "33/33 [==============================] - 62s 2s/step - loss: 1.6766 - CER: 0.0920 - WER: 0.3755 - val_loss: 7.0180 - val_CER: 0.2793 - val_WER: 0.8438 - lr: 0.0100\n",
      "Epoch 21/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 1.2273 - CER: 0.0624 - WER: 0.2659\n",
      "Epoch 21: val_CER improved from 0.17011 to 0.01388, saving model to /content/drive/MyDrive/captcha/model/202403281555/model.h5\n",
      "33/33 [==============================] - 63s 2s/step - loss: 1.2273 - CER: 0.0623 - WER: 0.2655 - val_loss: 0.2893 - val_CER: 0.0139 - val_WER: 0.0754 - lr: 0.0100\n",
      "Epoch 22/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 1.1228 - CER: 0.0550 - WER: 0.2340\n",
      "Epoch 22: val_CER did not improve from 0.01388\n",
      "33/33 [==============================] - 62s 2s/step - loss: 1.1228 - CER: 0.0549 - WER: 0.2338 - val_loss: 0.3390 - val_CER: 0.0170 - val_WER: 0.0954 - lr: 0.0100\n",
      "Epoch 23/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.8361 - CER: 0.0405 - WER: 0.1826\n",
      "Epoch 23: val_CER did not improve from 0.01388\n",
      "33/33 [==============================] - 61s 2s/step - loss: 0.8361 - CER: 0.0404 - WER: 0.1824 - val_loss: 0.5972 - val_CER: 0.0275 - val_WER: 0.1526 - lr: 0.0100\n",
      "Epoch 24/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.8246 - CER: 0.0353 - WER: 0.1655\n",
      "Epoch 24: val_CER improved from 0.01388 to 0.01277, saving model to /content/drive/MyDrive/captcha/model/202403281555/model.h5\n",
      "33/33 [==============================] - 64s 2s/step - loss: 0.8246 - CER: 0.0353 - WER: 0.1657 - val_loss: 0.2952 - val_CER: 0.0128 - val_WER: 0.0626 - lr: 0.0100\n",
      "Epoch 25/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.7402 - CER: 0.0328 - WER: 0.1555\n",
      "Epoch 25: val_CER improved from 0.01277 to 0.00436, saving model to /content/drive/MyDrive/captcha/model/202403281555/model.h5\n",
      "33/33 [==============================] - 65s 2s/step - loss: 0.7402 - CER: 0.0328 - WER: 0.1556 - val_loss: 0.1198 - val_CER: 0.0044 - val_WER: 0.0237 - lr: 0.0100\n",
      "Epoch 26/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.5895 - CER: 0.0255 - WER: 0.1241\n",
      "Epoch 26: val_CER improved from 0.00436 to 0.00213, saving model to /content/drive/MyDrive/captcha/model/202403281555/model.h5\n",
      "33/33 [==============================] - 65s 2s/step - loss: 0.5895 - CER: 0.0255 - WER: 0.1242 - val_loss: 0.0487 - val_CER: 0.0021 - val_WER: 0.0116 - lr: 0.0100\n",
      "Epoch 27/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.5690 - CER: 0.0252 - WER: 0.1222\n",
      "Epoch 27: val_CER improved from 0.00213 to 0.00122, saving model to /content/drive/MyDrive/captcha/model/202403281555/model.h5\n",
      "33/33 [==============================] - 65s 2s/step - loss: 0.5690 - CER: 0.0252 - WER: 0.1223 - val_loss: 0.0327 - val_CER: 0.0012 - val_WER: 0.0073 - lr: 0.0100\n",
      "Epoch 28/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.5976 - CER: 0.0267 - WER: 0.1292\n",
      "Epoch 28: val_CER did not improve from 0.00122\n",
      "33/33 [==============================] - 66s 2s/step - loss: 0.5976 - CER: 0.0266 - WER: 0.1292 - val_loss: 0.3816 - val_CER: 0.0213 - val_WER: 0.1204 - lr: 0.0100\n",
      "Epoch 29/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.4855 - CER: 0.0222 - WER: 0.1109\n",
      "Epoch 29: val_CER did not improve from 0.00122\n",
      "33/33 [==============================] - 63s 2s/step - loss: 0.4855 - CER: 0.0222 - WER: 0.1108 - val_loss: 0.1158 - val_CER: 0.0042 - val_WER: 0.0243 - lr: 0.0100\n",
      "Epoch 30/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.4587 - CER: 0.0191 - WER: 0.0988\n",
      "Epoch 30: val_CER did not improve from 0.00122\n",
      "33/33 [==============================] - 63s 2s/step - loss: 0.4587 - CER: 0.0191 - WER: 0.0988 - val_loss: 0.0660 - val_CER: 0.0021 - val_WER: 0.0128 - lr: 0.0100\n",
      "Epoch 31/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.5036 - CER: 0.0206 - WER: 0.1026\n",
      "Epoch 31: val_CER did not improve from 0.00122\n",
      "33/33 [==============================] - 64s 2s/step - loss: 0.5036 - CER: 0.0206 - WER: 0.1027 - val_loss: 0.0685 - val_CER: 0.0024 - val_WER: 0.0146 - lr: 0.0100\n",
      "Epoch 32/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.4855 - CER: 0.0221 - WER: 0.1099\n",
      "Epoch 32: val_CER did not improve from 0.00122\n",
      "33/33 [==============================] - 63s 2s/step - loss: 0.4855 - CER: 0.0221 - WER: 0.1096 - val_loss: 0.0540 - val_CER: 0.0020 - val_WER: 0.0116 - lr: 0.0100\n",
      "Epoch 33/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.3750 - CER: 0.0172 - WER: 0.0867\n",
      "Epoch 33: val_CER improved from 0.00122 to 0.00091, saving model to /content/drive/MyDrive/captcha/model/202403281555/model.h5\n",
      "33/33 [==============================] - 65s 2s/step - loss: 0.3750 - CER: 0.0172 - WER: 0.0865 - val_loss: 0.0318 - val_CER: 9.1185e-04 - val_WER: 0.0049 - lr: 0.0100\n",
      "Epoch 34/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.3465 - CER: 0.0155 - WER: 0.0823\n",
      "Epoch 34: val_CER did not improve from 0.00091\n",
      "33/33 [==============================] - 62s 2s/step - loss: 0.3465 - CER: 0.0155 - WER: 0.0822 - val_loss: 0.0554 - val_CER: 0.0019 - val_WER: 0.0109 - lr: 0.0100\n",
      "Epoch 35/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.4026 - CER: 0.0172 - WER: 0.0854\n",
      "Epoch 35: val_CER did not improve from 0.00091\n",
      "33/33 [==============================] - 63s 2s/step - loss: 0.4026 - CER: 0.0171 - WER: 0.0854 - val_loss: 0.0831 - val_CER: 0.0023 - val_WER: 0.0116 - lr: 0.0100\n",
      "Epoch 36/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.3458 - CER: 0.0140 - WER: 0.0734\n",
      "Epoch 36: val_CER did not improve from 0.00091\n",
      "33/33 [==============================] - 62s 2s/step - loss: 0.3458 - CER: 0.0140 - WER: 0.0734 - val_loss: 0.4769 - val_CER: 0.0154 - val_WER: 0.0626 - lr: 0.0100\n",
      "Epoch 37/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.3871 - CER: 0.0179 - WER: 0.0917\n",
      "Epoch 37: val_CER did not improve from 0.00091\n",
      "33/33 [==============================] - 61s 2s/step - loss: 0.3871 - CER: 0.0179 - WER: 0.0916 - val_loss: 0.0446 - val_CER: 0.0012 - val_WER: 0.0073 - lr: 0.0100\n",
      "Epoch 38/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.3217 - CER: 0.0136 - WER: 0.0727\n",
      "Epoch 38: val_CER did not improve from 0.00091\n",
      "33/33 [==============================] - 62s 2s/step - loss: 0.3217 - CER: 0.0136 - WER: 0.0727 - val_loss: 0.0558 - val_CER: 0.0017 - val_WER: 0.0097 - lr: 0.0100\n",
      "Epoch 39/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.2724 - CER: 0.0115 - WER: 0.0598\n",
      "Epoch 39: val_CER did not improve from 0.00091\n",
      "33/33 [==============================] - 65s 2s/step - loss: 0.2724 - CER: 0.0115 - WER: 0.0598 - val_loss: 0.0379 - val_CER: 0.0012 - val_WER: 0.0073 - lr: 0.0100\n",
      "Epoch 40/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.3016 - CER: 0.0116 - WER: 0.0626\n",
      "Epoch 40: val_CER did not improve from 0.00091\n",
      "33/33 [==============================] - 65s 2s/step - loss: 0.3016 - CER: 0.0116 - WER: 0.0627 - val_loss: 0.0505 - val_CER: 0.0017 - val_WER: 0.0097 - lr: 0.0100\n"
     ]
    }
   ]
  }
 ]
}
